# -*- coding: utf-8 -*-
"""Enablement_And_Engagement_of_Parents_at_work.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-sEGXSJnWBKcdm-Wjj7QLoP2rFOqKy4z
"""

import pandas as pd
import glob
'''
path = r'/content/drive/MyDrive/ipl_csv2' # use your path
all_files = glob.glob(path + "/*.csv")

li = []

for filename in all_files:
    df = pd.read_csv(filename, index_col=None, header=0)
    li.append(df)

frame = pd.concat(li, axis=0, ignore_index=True)
'''
frame = pd.read_csv('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Train.csv', index_col=None, header=0)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.ticker as ticker
import matplotlib.ticker as plticker
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

frame.head()

frame.describe()

!pip install pandas-profiling
!pip install sweetviz
!pip install autoviz
!pip install dtale

import pandas as pd
from autoviz.AutoViz_Class import AutoViz_Class

#EDA using Autoviz
autoviz = AutoViz_Class().AutoViz('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Train.csv')

import pandas as pd

import dtale
import dtale.app as dtale_app

dtale_app.USE_COLAB = True

dtale.show(pd.read_csv("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Train.csv"))
#dtale_report

import pandas as pd
import sweetviz as sv

#EDA using Autoviz
sweet_report = sv.analyze(pd.read_csv("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Train.csv"))

#Saving results to HTML file
sweet_report.show_html('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/sweetviz_report.html')

frame.info()

frame.head()

import nltk
nltk.download('vader_lexicon')
from nltk.sentiment.vader import SentimentIntensityAnalyzer
sid = SentimentIntensityAnalyzer()

from textblob import TextBlob
'''
# frame[0,12]
    # decide sentiment as positive, negative and neutral
    if sentiment_dict['compound'] >= 0.05 :
        print("Positive")
  
    elif sentiment_dict['compound'] <= - 0.05 :
        print("Negative")
  
    else :
        print("Neutral")
'''

sid.polarity_scores(frame.iloc[9]['Review Of Company'])

TextBlob(frame.iloc[9]['Review Of Company']).sentiment

print(frame.iloc[0:12]['Review Of Company'])

#frame['Review Sentiment']=[]
#for index, row in frame.iterrows():
#  Review_sentiment['Review Sentiment'] = sid.polarity_scores(frame.iloc[index]['Review Of Company'])

#frame['Review Sentiment']= Review_sentiment['Review Sentiment']
#frame.head()  
result = []
for value in frame["Review Of Company"]:
  sentiment_dict = sid.polarity_scores(value)
  if sentiment_dict['compound'] >= 0.05 :
    result.append("Positive")
  
  elif sentiment_dict['compound'] <= - 0.05 :
    result.append("Negative")
  
  else :
    result.append("Neutral")
       
frame["Review Of Company"] = result   
frame.head()

frame.head()
frame.drop(['Children Age'], axis = 1,inplace = True)
frame.head()

# Generate Normalized Encodings for batsmen , bowlers , Teams and Venues
li_WFH=frame['WFH Setup Available'].unique()
li_CompanyType=frame['Company Type'].unique()
li_Gender=frame['Gender'].unique()
li_Review=frame['Review Of Company'].unique()
li_Partner=frame['Partner'].unique()
li_Parent=frame['Is Parent'].unique()
li_Insurance=frame['Used Insurance'].unique()
li_Flexible=frame['Flexible Working Hours'].unique()
li_partnerWorking=frame['Partner Working'].unique()
li_Health=frame['Health Conditions'].unique()


en_WFH={}
en_CompanyType={}
en_Gender={}
en_Review={}
en_Partner={}
en_Parent={}
en_Insurance={}
en_Flexible={}
en_partnerWorking={}
en_Health={}
x=1

for i in li_WFH:
  en_WFH[i]=x
  x=x+1  
en_WFH = dict((k.lower(), v) for k, v in en_WFH.items()) 

x=1
for i in li_CompanyType:
  en_CompanyType[i]=x
  x=x+1  
en_CompanyType = dict((k.lower(), v) for k, v in en_CompanyType.items()) 

x=1
for i in li_Gender:
  en_Gender[i]=x
  x=x+1  
en_Gender = dict((k.lower(), v) for k, v in en_Gender.items()) 

x=1
for i in li_Review:
  en_Review[i]=x
  x=x+1  
en_Review = dict((k.lower(), v) for k, v in en_Review.items()) 

x=1
for i in li_Partner:
  en_Partner[i]=x
  x=x+1  
en_Partner = dict((k.lower(), v) for k, v in en_Partner.items()) 

x=1
for i in li_Parent:
  en_Parent[i]=x
  x=x+1  
en_Parent = dict((k.lower(), v) for k, v in en_Parent.items()) 

x=1
for i in li_Insurance:
  en_Insurance[i]=x
  x=x+1  
en_Insurance = dict((k.lower(), v) for k, v in en_Insurance.items()) 

x=1
for i in li_Flexible:
  en_Flexible[i]=x
  x=x+1  
en_Flexible = dict((k.lower(), v) for k, v in en_Flexible.items()) 

x=1
for i in li_partnerWorking:
  en_partnerWorking[i]=x
  x=x+1  
en_partnerWorking = dict((k.lower(), v) for k, v in en_partnerWorking.items()) 

x=1
for i in li_Health:
  en_Health[i]=x
  x=x+1  
en_Health = dict((k.lower(), v) for k, v in en_Health.items())

# Convert the column values to lower
frame['WFH Setup Available'] = frame['WFH Setup Available'].str.lower()
frame['Company Type'] = frame['Company Type'].str.lower()          
frame['Gender']  = frame['Gender'].str.lower()               
frame['Review Of Company'] = frame['Review Of Company'].str.lower()     
frame['Partner']  = frame['Partner'].str.lower()               
frame['Is Parent']  = frame['Is Parent'].str.lower()             
frame['Used Insurance']  = frame['Used Insurance'].str.lower()        
frame['Flexible Working Hours'] = frame['Flexible Working Hours'].str.lower() 
frame['Partner Working'] = frame['Partner Working'].str.lower()        
frame['Health Conditions']  = frame['Health Conditions'].str.lower()

## Encode columns in final dataframe

frame['WFH Setup Available'] = frame['WFH Setup Available'].map(en_WFH)
frame['Company Type'] = frame['Company Type'].map(en_CompanyType)          
frame['Gender']  = frame['Gender'].map(en_Gender)               
frame['Review Of Company'] = frame['Review Of Company'].map(en_Review)     
frame['Partner']  = frame['Partner'].map(en_Partner)               
frame['Is Parent']  = frame['Is Parent'].map(en_Parent)             
frame['Used Insurance']  = frame['Used Insurance'].map(en_Insurance)        
frame['Flexible Working Hours'] = frame['Flexible Working Hours'].map(en_Flexible) 
frame['Partner Working'] = frame['Partner Working'].map(en_partnerWorking)        
frame['Health Conditions']  = frame['Health Conditions'].map(en_Health)

frame.head()

frame.describe()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.ticker as ticker
import matplotlib.ticker as plticker
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

import pickle
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

'''
en_WFH={}
en_CompanyType={}
en_Gender={}
en_Review={}
en_Partner={}
en_Parent={}
en_Insurance={}
en_Flexible={}
en_partnerWorking={}
en_Health={}
'''
a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_WFH.pkl", "wb")
pickle.dump(en_WFH, a_file)
a_file.close()

a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_CompanyType.pkl", "wb")
pickle.dump(en_CompanyType, a_file)
a_file.close()

a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Gender.pkl", "wb")
pickle.dump(en_Gender, a_file)
a_file.close()

a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Review.pkl", "wb")
pickle.dump(en_Review, a_file)
a_file.close()

a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Partner.pkl", "wb")
pickle.dump(en_Partner, a_file)
a_file.close()


a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Parent.pkl", "wb")
pickle.dump(en_Parent, a_file)
a_file.close()

a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Insurance.pkl", "wb")
pickle.dump(en_Insurance, a_file)
a_file.close()

a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Flexible.pkl", "wb")
pickle.dump(en_Flexible, a_file)
a_file.close()

a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_partnerWorking.pkl", "wb")
pickle.dump(en_partnerWorking, a_file)
a_file.close()

a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Health.pkl", "wb")
pickle.dump(en_Health, a_file)
a_file.close()


a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Review.pkl", "rb")
output = pickle.load(a_file)
print(output)

frame.head()

final_frame = frame.drop(['Employee ID','Learning New Thing','Hours Worked Last Week','Completed Task Last Week'], axis = 1)
final_frame['Assigned Work Hours']= final_frame['Assigned Work Hours']/final_frame['Assigned Work Hours'].max()
final_frame['Assigned Task Last Week']= final_frame['Assigned Task Last Week']/final_frame['Assigned Task Last Week'].max()
final_frame['Leaves Available']= final_frame['Leaves Available']/final_frame['Leaves Available'].max()
final_frame.head()

## inplace = True
final_frame = final_frame.drop(['Company Type','Health Conditions','Partner Working','Used Insurance','WFH Setup Available','Flexible Working Hours','Partner','Is Parent'], axis = 1)
final_frame = final_frame.drop(['Designation','Review Of Company','Gender'], axis = 1)

final_frame.info()

# multi-class classification with Keras
import pandas
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
# load dataset
import numpy as np

len_col = len(final_frame.columns)
print(len_col)
labels=final_frame['Support']
features = final_frame.iloc[:,0:len_col-1]
#print(features[0:2])
from sklearn.model_selection import train_test_split

X=features.astype(float)
#y=np.ravel(labels)
labels_temp = labels.copy()
encoder = LabelEncoder()
encoder.fit(labels)
Y = encoder.transform(labels)
from tensorflow.keras import utils
y = utils.to_categorical(Y)


np.save('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Feature_5_Y_classes.npy', encoder.classes_) 
'''
To Test and Decode:
encoder = LabelEncoder()
encoder.classes_ = np.load('classes.npy')

lb = LabelEncoder()
Y = encoder.inverse_transform(y_pred)
# Now you should be able to use encoder
# as you would do after `fit`
'''

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)



print(len(X_train) )
print(len(y_train) )
print(y[0:9])
print(Y[0:9])
print(encoder.inverse_transform(Y[0:9]))

#  normalize the values
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler().fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

X_ROW, X_COL =  X_train.shape
Y_ROW, Y_COL = y_train.shape
print("X dim: ", X_ROW ,'x',X_COL)
print("Y dim: ", Y_ROW,'x',Y_COL)

# Train model and make predictions
import numpy
import pandas
from keras.models import Sequential, model_from_json
from keras.layers import Dense
from keras.utils import np_utils
from sklearn import datasets
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
def build_model():
    # create model
    model = Sequential()
    model.add(Dense(24, input_shape=(X_COL,),  activation='relu'))
    model.add(Dense(12, activation='relu'))
    model.add(Dense(Y_COL, activation='sigmoid'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

def save_model(model):
    # saving model
    json_model = model.to_json()
    open('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Feature_5_model_architecture.json', 'w').write(json_model)
    # saving weights
    model.save_weights('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Feature_5_model_weights.h5', overwrite=True)

def load_model():
    # loading model
    model = model_from_json(open('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Feature_5_model_architecture.json').read())
    model.load_weights('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Feature_5_model_weights.h5')
    model.compile(loss='categorical_crossentropy', optimizer='adam')
    return model


#X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=seed)

# build
model = build_model()
model.fit(X_train, y_train, epochs=20, batch_size=10, verbose=1)

# save
save_model(model)

# load
model = load_model()

# predictions
y_pred = model.predict_classes(X_test, verbose=0)
print(y_pred)
encoder = LabelEncoder()
encoder.classes_ = np.load('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Feature_5_Y_classes.npy', allow_pickle=True)
Y = encoder.inverse_transform(y_pred[0:9])
print(Y[0:9])
# reverse encoding
#for pred in predictions:
 #   print(labels[pred])

from sklearn.ensemble import RandomForestClassifier

# Create the model with 100 trees
rf_model = RandomForestClassifier(n_estimators=100, 
                               bootstrap = True,
                               max_features = 'sqrt')
# Fit on training data
rf_model.fit(X_train, y_train)

# save the model to disk
filename_2 = '/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/RF_5_features_Classifier_model.sav'
pickle.dump(rf_model, open(filename_2, 'wb'))

import pandas as pd

# Extract feature importances
fi = pd.DataFrame({'feature': list(X.columns),
                   'importance': rf_model.feature_importances_}).\
                    sort_values('importance', ascending = False)

# Display
fi.head(16)

def load_model():
    # loading model
    model = model_from_json(open('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/model_architecture.json').read())
    model.load_weights('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/model_weights.h5')
    model.compile(loss='categorical_crossentropy', optimizer='adam')
    return model

def Predict_Support(filename='/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Test.csv'):
  encoder = LabelEncoder()
  encoder.classes_ = np.load('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Y_classes.npy', allow_pickle=True)
  
  '''
  en_WFH={}
  en_CompanyType={}
  en_Gender={}
  en_Review={}
  en_Partner={}
  en_Parent={}
  en_Insurance={}
  en_Flexible={}
  en_partnerWorking={}
  en_Health={}
  '''
  a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_WFH.pkl", "rb")
  en_WFH = pickle.load(a_file)
  a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_CompanyType.pkl", "rb")
  en_CompanyType = pickle.load(a_file)
  a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Gender.pkl", "rb")
  en_Gender = pickle.load(a_file)
  a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Review.pkl", "rb")
  en_Review = pickle.load(a_file)
  a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Partner.pkl", "rb")
  en_Partner = pickle.load(a_file)
  a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Parent.pkl", "rb")
  en_Parent = pickle.load(a_file)
  a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Insurance.pkl", "rb")
  en_Insurance = pickle.load(a_file)
  a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Flexible.pkl", "rb")
  en_Flexible = pickle.load(a_file)
  a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_partnerWorking.pkl", "rb")
  en_partnerWorking = pickle.load(a_file)
  a_file = open("/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/en_Health.pkl", "rb")
  en_Health = pickle.load(a_file)
  
  Orig_Frame = pd.read_csv(filename, index_col=None, header=0)
  test_frame = pd.read_csv(filename, index_col=None, header=0)

  import nltk
  nltk.download('vader_lexicon')
  from nltk.sentiment.vader import SentimentIntensityAnalyzer
  sid = SentimentIntensityAnalyzer()
  #frame.head()  
  result = []
  for value in test_frame["Review Of Company"]:
    sentiment_dict = sid.polarity_scores(value)
    if sentiment_dict['compound'] >= 0.05 :
      result.append("Positive")
  
    elif sentiment_dict['compound'] <= - 0.05 :
      result.append("Negative")
  
    else :
      result.append("Neutral")

  test_frame["Review Of Company"] = result   
  test_frame.head()
  test_frame.drop(['Children Age'], axis = 1,inplace = True)

  # Convert the column values to lower
  test_frame['WFH Setup Available'] = test_frame['WFH Setup Available'].str.lower()
  test_frame['Company Type'] = test_frame['Company Type'].str.lower()          
  test_frame['Gender']  = test_frame['Gender'].str.lower()               
  test_frame['Review Of Company'] = test_frame['Review Of Company'].str.lower()     
  test_frame['Partner']  = test_frame['Partner'].str.lower()               
  test_frame['Is Parent']  = test_frame['Is Parent'].str.lower()             
  test_frame['Used Insurance']  = test_frame['Used Insurance'].str.lower()        
  test_frame['Flexible Working Hours'] = test_frame['Flexible Working Hours'].str.lower() 
  test_frame['Partner Working'] = test_frame['Partner Working'].str.lower()        
  test_frame['Health Conditions']  = test_frame['Health Conditions'].str.lower()

  ## Encode columns in final dataframe

  test_frame['WFH Setup Available'] = test_frame['WFH Setup Available'].map(en_WFH)
  test_frame['Company Type'] = test_frame['Company Type'].map(en_CompanyType)          
  test_frame['Gender']  = test_frame['Gender'].map(en_Gender)               
  test_frame['Review Of Company'] = test_frame['Review Of Company'].map(en_Review)     
  test_frame['Partner']  = test_frame['Partner'].map(en_Partner)               
  test_frame['Is Parent']  = test_frame['Is Parent'].map(en_Parent)             
  test_frame['Used Insurance']  = test_frame['Used Insurance'].map(en_Insurance)        
  test_frame['Flexible Working Hours'] = test_frame['Flexible Working Hours'].map(en_Flexible) 
  test_frame['Partner Working'] = test_frame['Partner Working'].map(en_partnerWorking)        
  test_frame['Health Conditions']  = test_frame['Health Conditions'].map(en_Health)   

  test_frame = test_frame.drop(['Employee ID','Learning New Thing','Hours Worked Last Week','Completed Task Last Week'], axis = 1)
  test_frame['Assigned Work Hours']= test_frame['Assigned Work Hours']/test_frame['Assigned Work Hours'].max()
  test_frame['Assigned Task Last Week']= test_frame['Assigned Task Last Week']/test_frame['Assigned Task Last Week'].max()
  test_frame['Leaves Available']= test_frame['Leaves Available']/test_frame['Leaves Available'].max()
  print(test_frame.head())
  
  test_X=test_frame.astype(float)
  print('X shape : ', test_X.shape)
  model = load_model()
  # predictions
  test_y = model.predict_classes(test_X, verbose=0)
  print(test_y)
  encoder = LabelEncoder()
  encoder.classes_ = np.load('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Y_classes.npy', allow_pickle=True)
  Y = encoder.inverse_transform(test_y)
  
  Orig_Frame['Support']=Y
  Orig_Frame.to_csv('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Test_submit.csv')
  print(Y[0:9])

Predict_Support('/content/drive/MyDrive/CTRL_HACK_DEL/IDEA_Submissions/Enablement_and_Engagement_of_Parents_at_Work/Test.csv')